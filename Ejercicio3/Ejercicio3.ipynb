{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd88412-c035-48a9-af6a-09bc1d194d36",
   "metadata": {},
   "source": [
    "### Ejercicio 3 : (Este ejercicio debe realizarse con archivos csv,json,parquet)\n",
    "- [x] Leer archivo en DataFrame\n",
    "- [x] Desplegar DataFrame\n",
    "- [x] Escribir DataFrame en archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57924583-5e06-4947-82c3-33e21bb8112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"Exercise3\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c5d4aa4-fe9e-468f-bd8a-b95ec65b4a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame CSV as part:\n",
      "+-------+---+------+\n",
      "|   Name|Age|Gender|\n",
      "+-------+---+------+\n",
      "|Shirley| 22|     M|\n",
      "|Jasmine| 50|     M|\n",
      "|  David| 19|     M|\n",
      "|   Mark| 25|     M|\n",
      "+-------+---+------+\n",
      "\n",
      "DataFrame CSV as single file:\n",
      "+-------+---+------+\n",
      "|   Name|Age|Gender|\n",
      "+-------+---+------+\n",
      "|  David| 19|     M|\n",
      "|   Mark| 25|     M|\n",
      "|Shirley| 22|     M|\n",
      "|Jasmine| 50|     M|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_csv = spark.read.csv(\"data2.csv\", header=True, inferSchema=True)\n",
    "df_csv = spark.read.csv(\"data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(\"DataFrame CSV as part:\")\n",
    "df2_csv.show()\n",
    "\n",
    "print(\"DataFrame CSV as single file:\")\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6caf5157-7701-410b-8113-796f7389d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame JSON as part:\n",
      "+---+------+-------+\n",
      "|Age|Gender|   Name|\n",
      "+---+------+-------+\n",
      "| 22|     M|Shirley|\n",
      "| 50|     M|Jasmine|\n",
      "| 19|     M|  David|\n",
      "| 25|     M|   Mark|\n",
      "+---+------+-------+\n",
      "\n",
      "DataFrame JSON as single file:\n",
      "+---+------+-------+\n",
      "|Age|Gender|   Name|\n",
      "+---+------+-------+\n",
      "| 19|     M|  David|\n",
      "| 25|     M|   Mark|\n",
      "| 22|     M|Shirley|\n",
      "| 50|     M|Jasmine|\n",
      "+---+------+-------+\n",
      "\n",
      "root\n",
      " |-- Age: long (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_json = spark.read.json(\"data2.json\")\n",
    "df_json = spark.read.json(\"data.json\", multiLine=True)\n",
    "\n",
    "print(\"DataFrame JSON as part:\")\n",
    "df2_json.show()\n",
    "\n",
    "print(\"DataFrame JSON as single file:\")\n",
    "df_json.show()\n",
    "\n",
    "df_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13a5ac3d-3b19-4d96-923d-b74886534fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Parquet as part:\n",
      "+-------+---+------+\n",
      "|   Name|Age|Gender|\n",
      "+-------+---+------+\n",
      "|Jasmine| 50|     M|\n",
      "|Shirley| 22|     M|\n",
      "|  David| 19|     M|\n",
      "|   Mark| 25|     M|\n",
      "+-------+---+------+\n",
      "\n",
      "DataFrame Parquet as single file:\n",
      "+-------+---+------+\n",
      "|   Name|Age|Gender|\n",
      "+-------+---+------+\n",
      "|Jasmine| 50|     M|\n",
      "|Shirley| 22|     M|\n",
      "|  David| 19|     M|\n",
      "|   Mark| 25|     M|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet = spark.read.parquet(\"data2.parquet\")\n",
    "df2_parquet = spark.read.parquet(\"data2.parquet\")\n",
    "\n",
    "print(\"DataFrame Parquet as part:\")\n",
    "df_parquet.show()\n",
    "\n",
    "print(\"DataFrame Parquet as single file:\")\n",
    "df2_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "932662bc-d588-4a9a-9433-42b9ce0c2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.write.csv(\"result_csv\", header=True)\n",
    "df_csv.coalesce(1).write.csv(\"result2_csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e18b146a-8b1c-4042-948c-c9a91d1f8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = df_json.toPandas().to_dict(orient=\"records\")\n",
    "\n",
    "with open(\"result2.json\", \"w\") as json_file:\n",
    "    json.dump(json_list, json_file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "num_records = df_json.count()\n",
    "df_repartitioned = df_json.repartition(num_records)\n",
    "df_repartitioned.write.mode(\"overwrite\").json(\"partitioned_json_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61374b23-4d91-4a49-aa6c-e86c6b785437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet.write.parquet(\"result_parquet\")\n",
    "df_parquet.coalesce(1).write.parquet(\"result2_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f41c4822-c357-4eca-96bb-f311c177f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_single_file(temp_dir, output_file):\n",
    "    for file_name in os.listdir(temp_dir):\n",
    "        if file_name.endswith(\".json\") or file_name.endswith(\".csv\") or file_name.endswith(\".parquet\"):\n",
    "            shutil.move(os.path.join(temp_dir, file_name), output_file)\n",
    "            break\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "move_single_file(\"result2_csv\", \"result.csv\")\n",
    "move_single_file(\"result2_parquet\", \"result.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "295e1ee5-44d5-483a-9ab2-1ac8e2bb36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a63837b-bb8f-4a3d-b806-e0be0c4d42e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
